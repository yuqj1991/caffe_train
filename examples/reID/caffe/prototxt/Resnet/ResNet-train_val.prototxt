name: "ResNet-18-train"

layer {
	name: "data"
	type: "ccpdData"
	top: "data"
	top: "label"
	include {
		phase: TRAIN
	}
	transform_param {
		scale: 0.007843
		mirror: false
		mean_value: 127.5
		mean_value: 127.5
		mean_value: 127.5
		resize_param {
			prob: 1.0
			resize_mode: WARP
			height: 32
			width: 128
			interp_mode: LINEAR
			interp_mode: AREA
			interp_mode: NEAREST
			interp_mode: CUBIC
			interp_mode: LANCZOS4
		}
		emit_constraint {
			emit_type: CENTER
		}
		distort_param {
			brightness_prob: 0.5
			brightness_delta: 32.0
			contrast_prob: 0.5
			contrast_lower: 0.5
			contrast_upper: 1.5
			hue_prob: 0.5
			hue_delta: 18.0
			saturation_prob: 0.5
			saturation_lower: 0.5
			saturation_upper: 1.5
			random_order_prob: 0.0
		}
		expand_param {
			prob: 0.5
			max_expand_ratio: 2.0
		}
	}
	data_param {
		source: "../../../../dataset/car_person_data/car_license/ccpd_dataset/lmdb/ccpd_dataset_training_lp_lmdb/"
		batch_size: 128
		backend: LMDB
	}
}

layer {
	name: "data"
	type: "ccpdData"
	top: "data"
	top: "label"
	include {
		phase: TEST
	}
	transform_param {
		scale: 0.007843
		mean_value: 127.5
		mean_value: 127.5
		mean_value: 127.5
		resize_param {
			prob: 1.0
			resize_mode: WARP
			height: 32
			width: 128
			interp_mode: LINEAR
		}
	}
	data_param {
		source: "../../../../dataset/car_person_data/car_license/ccpd_dataset/lmdb/ccpd_dataset_testing_lp_lmdb/"
		batch_size: 4
		backend: LMDB
	}
}

layer {
  bottom: "data"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 5
      pad: 2
      stride: 2
	  weight_filler { type: "msra" std: 0.010 }
	  bias_filler { type: "constant" value: 0 }
      }
}

layer {
  bottom: "conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "conv1"
    top: "conv1"
    name: "scale_conv1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "conv1"
    top: "conv1"
    name: "conv1_relu"
    type: "ReLU"
    }

layer {
  bottom: "conv1"
    top: "pool1"
    name: "pool1"
    type: "Pooling"
    pooling_param {
    kernel_size: 3
      stride: 2
      pool: MAX
      }
}
##########################
######first shortcut######
##########################
layer {
  bottom: "pool1"
    top: "res2a_branch1"
    name: "res2a_branch1"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 1
      pad: 0
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "bn2a_branch1"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "scale2a_branch1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "pool1"
    top: "res2a_branch2a"
    name: "res2a_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 32
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "bn2a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "scale2a_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "res2a_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2b"
    name: "res2a_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "bn2a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "scale2a_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
    bottom: "res2a_branch1"
    bottom: "res2a_branch2b"
    top: "res2a"
    name: "res2a"
    type: "Eltwise"
    }

layer {
  bottom: "res2a"
    top: "res2a"
    name: "res2a_relu"
    type: "ReLU"
    }

layer {
    bottom: "res2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 32
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "bn2b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "scale2b_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2b"
    name: "res2b_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "bn2b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "scale2b_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2a"
    bottom: "res2b_branch2b"
    top: "res2b"
    name: "res2b"
    type: "Eltwise"
    }

layer {
  bottom: "res2b"
    top: "res2b"
    name: "res2b_relu"
    type: "ReLU"
    }


##########################
######second shortcut#####
##########################

layer {
  bottom: "res2b"
    top: "res3a_branch1"
    name: "res3a_branch1"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 1
      pad: 0
      stride: 2
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "bn3a_branch1"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "scale3a_branch1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2b"
    top: "res3a_branch2a"
    name: "res3a_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 32
      kernel_size: 3
      pad: 1
      stride: 2
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "bn3a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "scale3a_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "res3a_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2b"
    name: "res3a_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "bn3a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "scale3a_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch1"
    bottom: "res3a_branch2b"
    top: "res3a"
    name: "res3a"
    type: "Eltwise"
    }

layer {
  bottom: "res3a"
    top: "res3a"
    name: "res3a_relu"
    type: "ReLU"
    }


layer {
  bottom: "res3a"
    top: "res3b_branch2a"
    name: "res3b_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "bn3b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "scale3b_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "res3b_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2b"
    name: "res3b_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "bn3b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "scale3b_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3a"
    bottom: "res3b_branch2b"
    top: "res3b"
    name: "res3b"
    type: "Eltwise"
    }

layer {
  bottom: "res3b"
    top: "res3b"
    name: "res3b_relu"
    type: "ReLU"
    }
##########################
######third shortcut#####
##########################

layer {
  bottom: "res3b"
    top: "res4a_branch1"
    name: "res4a_branch1"
    type: "Convolution"
    convolution_param {
    num_output: 128
      kernel_size: 1
      pad: 0
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "bn4a_branch1"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "scale4a_branch1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3b"
    top: "res4a_branch2a"
    name: "res4a_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "bn4a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "scale4a_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "res4a_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2b"
    name: "res4a_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 128
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "bn4a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "scale4a_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch1"
    bottom: "res4a_branch2b"
    top: "res4a"
    name: "res4a"
    type: "Eltwise"
    }

layer {
  bottom: "res4a"
    top: "res4a"
    name: "res4a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res4a"
    top: "res4b_branch2a"
    name: "res4b_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "bn4b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "scale4b_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "res4b_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2b"
    name: "res4b_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 128
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "bn4b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
    use_global_stats: false
      }
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "scale4b_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4a"
    bottom: "res4b_branch2b"
    top: "res4b"
    name: "res4b"
    type: "Eltwise"
    }

layer {
  bottom: "res4b"
    top: "res4b"
    name: "res4b_relu"
    type: "ReLU"
    }

layer {
  name: "pool5_ave"
  type: "Pooling"
  bottom: "res4b"
  top: "pool5_ave"
  pooling_param {
    pool: AVE
    kernel_w: 1
	kernel_h: 4
    stride_w: 1
	stride_h: 1
  }
}

layer {
  name: "pool5_ave_transpose"
  top: "pool5_ave_transpose"
  bottom: "pool5_ave"
  type: "Transpose"
  transpose_param {
    dim: 3
    dim: 2
    dim: 0
    dim: 1
  }
}

layer {
  name: "blstm_input"
  type: "Reshape"
  bottom: "pool5_ave_transpose"
  top: "blstm_input"
  reshape_param {
    shape { dim: -1 }
    axis: 1
    num_axes: 2
  }
}

#===================blstm layer 1============================
#======lstm1===================
layer {
  name: "lstm1"
  type: "Lstm"
  bottom: "blstm_input"
  top: "lstm1"
  lstm_param {
    num_output: 100
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}

# =====lstm1_reverse===================
layer {
  name: "lstm1-reverse1"
  type: "Reverse"
  bottom: "blstm_input"
  top: "rlstm1_input"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "rlstm1"
  type: "Lstm"
  bottom: "rlstm1_input"
  top: "rlstm1-output"
  lstm_param {
    num_output: 100
	weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
   }
}
layer {
  name: "lstm1-reverse2"
  type: "Reverse"
  bottom: "rlstm1-output"
  top: "rlstm1"
  reverse_param {
    axis: 0
  }
}


# merge lstm1 and rlstm1
layer {
  name: "blstm1"
  type: "Concat"
  bottom: "lstm1"
  bottom: "rlstm1"
  top: "blstm1"
  concat_param {
    axis: 2
  }
}


 

#===================blstm layer 2============================
#======lstm2===================
layer {
  name: "lstm2"
  type: "Lstm"
  bottom: "blstm1"
  top: "lstm2"
  lstm_param {
    num_output: 100
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}

# =====lstm2_reverse===================
layer {
  name: "lstm2-reverse1"
  type: "Reverse"
  bottom: "blstm1"
  top: "rlstm2_input"
  reverse_param {
    axis: 0
  }
}

layer {
  name: "rlstm2"
  type: "Lstm"
  bottom: "rlstm2_input"
  top: "rlstm2-output"
  lstm_param {
    num_output: 100
	weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
   }
}
layer {
  name: "lstm2-reverse2"
  type: "Reverse"
  bottom: "rlstm2-output"
  top: "rlstm2"
  reverse_param {
    axis: 0
  }
}

# merge lstm2 and rlstm2
layer {
	name: "blstm2"
	type: "Concat"
	bottom: "lstm2"
	bottom: "rlstm2"
	top: "blstm2"
	concat_param {
		axis: 2
	}
}

layer {
	name: "blstm_sum"
	type: "Eltwise"
	bottom: "blstm1"
	bottom: "blstm2"
	top: "blstm_sum"
	eltwise_param{
		operation: SUM
	}
}

 


layer {
	name: "fc1x"
	type: "InnerProduct"
	bottom: "blstm_sum"
	top: "fc1x"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	inner_product_param {
		axis: 2
		num_output: 66
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}


layer {
	name: "ctcloss"
	type: "WarpCTCLoss"
	bottom: "fc1x"
	bottom: "label"
	top: "ctcloss"
	loss_weight:1
}

layer {
	name: "acc"
	type: "CTCGreedyDecoder"
	bottom: "fc1x"
	bottom: "label"
	top: "acc"
	include {
		phase: TEST
	}
}
